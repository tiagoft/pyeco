{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "Machine Learning is a field of Artificial Intelligence that comprises building general-purpose machines that specialize when they learn from data. But, what does \"learn from data\" mean?\n",
    "\n",
    "Machine Learning can be seen as a mixture of statistics and linear algebra - although statistics definitely plays a more important role here.\n",
    "\n",
    "When we build models from data, we are assuming that this data is comprised of samples that come some unknown distribution. We can call our samples $x$ and our distribution $X$, so that:\n",
    "\n",
    "$$\n",
    "x \\sim P(X)\n",
    "$$\n",
    "\n",
    "If we knew the distribution $P(X)$, we could estimate, for example, the probability that a sample has some value or range of values (for example: $P(a \\leq x \\lt b)$), and this could be very useful. For example, if we could reliably find the distribution of gains for a particular trading strategy, we would be able to know the probability of gaining between $a$ and $b$ amounts in a particular day. Then, we could make a call on whether or not the potential gains of implementing that strategy would surpass its risks and inherent cost.\n",
    "\n",
    "The problem is that is it usually very hard to find the distribution $P(X)$.\n",
    "\n",
    "In fact, even if we *knew* the distribution is normal, and if we *knew* its variance, just estimating its mean would be a difficult task. Let's take a closer look.\n",
    "\n",
    "## The Central Limit Theorem\n",
    "\n",
    "The Central Limit Theorem (CLT) states that, if we have a sample $x$ of size $n$, independently drawn from a distribution with mean $\\mu$ and variance $\\sigma^2$, then the sample mean $\\bar{x}$ of $x$ follows a normal distribution, as:\n",
    "\n",
    "$$\n",
    "\\bar{x} \\sim N(\\mu, \\frac{\\sigma^2}{N})\n",
    "$$\n",
    "\n",
    "Check this demonstration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "calculated_x_bar = []\n",
    "for i in range(1000):\n",
    "    x = np.random.exponential(size=(50,)) # Get 50 samples from a distribution\n",
    "    xbar = np.mean(x) # Calculate the sample mean\n",
    "    calculated_x_bar.append(xbar) # Same the sample mean\n",
    "\n",
    "plt.figure(figsize=(4,2))\n",
    "plt.hist(calculated_x_bar) # This is the histogram of sample means\n",
    "plt.title('Central Limit Theorem Demo')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What this is showing is that, even if we *knew* the distribution that is generating data, we still struggle to estimate its parameters from data.\n",
    "\n",
    "In fact, if we estimate our distribution mean twice, we could get values from $0.6$ to $1.4$, which is a huge difference, considering that the true value is $1$.\n",
    "\n",
    "## We need more data\n",
    "\n",
    "You have probably heard people claiming that using more data is *better*. This could be true. In fact, we can show it. According to the central limit theorem, the estimated mean of our samples is:\n",
    "\n",
    "$$\n",
    "\\bar{x} \\sim N(\\mu, \\frac{\\sigma^2}{N})\n",
    "$$\n",
    "\n",
    "which means that increasing $N$ leads to decreasing the sample variance of $\\bar{x}$, thus $\\bar{x}$ is more likely to be closer to the mean.\n",
    "\n",
    "Let's view it in practice:\n",
    "\n",
    "**Exercise: get MORE data!**\n",
    "\n",
    "Go back to the code excerpt above demonstrating the CLT. What happens if we increase the number of samples acquired in each round? Is it the predicted effect of the CLT?\n",
    "\n",
    "## We need ~~more~~ BETTER data\n",
    "\n",
    "In fact, increasing the number of data points is usually a very good way to increase the accuracy of our estimates. However, sometimes that is simply not possible: we cannot increase a village's population, the size of a classroom, we cannot redo the historical process that lead countries to be where they are, we cannot find arbitrarily more customers or users to a product, and so on.\n",
    "\n",
    "If we look at the CLT again:\n",
    "\n",
    "$$\n",
    "\\bar{x} \\sim N(\\mu, \\frac{\\sigma^2}{N})\n",
    "$$\n",
    "\n",
    "we can see that, instead of increasing $N$, we could decrease $\\sigma$. In practice, this means: \"we will estimate distributions by sampling features that make more sense towards our problem\". For example: we could make a model for the height of all students in our class. However, we could actually break down our students according to, for example, some grouping process. We might find that dividing our data among male and female students, for example, could lead to groups with significantly lower variance.\n",
    "\n",
    "But, note - in this case, we are not estimating $P(X)$ anymore. Rather, we are assuming each element in our sample has a property called \"class\". We will model our class as another random variable, $C$, and in this case it can assume two different values: $c_1$ for male, or $c_2$ for female. Thus, we are actually estimating a *conditional* distribution, that is, our samples $x$ are drawn from:\n",
    "\n",
    "$$\n",
    "x \\sim P(X | C)\n",
    "$$\n",
    "\n",
    "Thus, we sample from the distribution while *knowing* the class for each element of the group.\n",
    "\n",
    "## Bayes' Theorem\n",
    "\n",
    "Remember Bayes' Theorem? This is it:\n",
    "\n",
    "$$\n",
    "P(X|C) P(C) = P(C|X) P(X)\n",
    "$$\n",
    "\n",
    "In fact, that means that, given an observation $X$, we can calculate the probability of that element having class $C$, as:\n",
    "\n",
    "$$\n",
    "P(C|X) = \\frac{P(X|C) P(C)}{P(X)}\n",
    "$$\n",
    "\n",
    "So we can have an idea here: we could *observe* parameters $X$ for an element of our dataset, and then estimate the probability $P(C|X)$ for each possible class. For such, we need to have had first estimated $P(X|C)$, $P(X)$ and $P(C)$. To estimate them, we need:\n",
    "\n",
    "* A sample that is representative of the population you want to estimate the distribution on\n",
    "* Labels (defining the class) for each element of that sample\n",
    "\n",
    "If the distributions are discrete, then we can simply estimate the probabilities by counting.\n",
    "\n",
    "## Application: sentiment analysis\n",
    "\n",
    "Not rarely, companies (and, nowadays, influencers and governments) wish to know if people are saying unpleasant things about them online. For this exercise, I have created a fictional company called FinMonday, which is a fintech we use on our classes on Monday mornings. FinMonday has had a series of victories in the recent news, but also a series of accusations of fraud. Our fictional intern gathered and labeled some news about FinMonday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "news",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "sentiment",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0180aa45-8e11-4fe9-8cb1-24d1c6543765",
       "rows": [
        [
         "0",
         "FinMonday achieves a major gain in the fintech sector, surpassing revenue expectations for the third quarter.",
         "positive"
        ],
        [
         "1",
         "A strategic partnership with global banks marks another victory for FinMonday, solidifying its position as a market leader.",
         "positive"
        ],
        [
         "2",
         "FinMonday celebrates a victory after its latest AI-driven investment tool gains widespread industry adoption.",
         "positive"
        ],
        [
         "3",
         "Victory for FinMonday as the company secures regulatory approval for its innovative blockchain-based transactions.",
         "positive"
        ],
        [
         "4",
         "FinMonday reports record profits, marking a significant victory for investors and stakeholders alike.",
         "positive"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FinMonday achieves a major gain in the fintech...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A strategic partnership with global banks mark...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FinMonday celebrates a victory after its lates...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Victory for FinMonday as the company secures r...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FinMonday reports record profits, marking a si...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news sentiment\n",
       "0  FinMonday achieves a major gain in the fintech...  positive\n",
       "1  A strategic partnership with global banks mark...  positive\n",
       "2  FinMonday celebrates a victory after its lates...  positive\n",
       "3  Victory for FinMonday as the company secures r...  positive\n",
       "4  FinMonday reports record profits, marking a si...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd \n",
    "news = [{\n",
    "    \"news\":\n",
    "    \"FinMonday achieves a major gain in the fintech sector, surpassing revenue expectations for the third quarter.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"A strategic partnership with global banks marks another victory for FinMonday, solidifying its position as a market leader.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"FinMonday celebrates a victory after its latest AI-driven investment tool gains widespread industry adoption.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"Victory for FinMonday as the company secures regulatory approval for its innovative blockchain-based transactions.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"FinMonday reports record profits, marking a significant victory for investors and stakeholders alike.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"Another victory for FinMonday as it expands its market presence to Europe, increasing its global footprint.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"FinMonday's stock price surges after a victory in court clears the company of previous legal uncertainties.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"A major victory for FinMonday as customer satisfaction reaches an all-time high, according to a new survey.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"FinMonday's strategic acquisition of a promising startup is seen as a victory that will fuel further innovation.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"Victory for FinMonday as its mobile banking app receives top ratings and recognition from industry experts.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"FinMonday secures a major investment, marking a financial victory that boosts its expansion plans.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"A victory for FinMonday as its CEO is recognized as one of the top leaders in the financial industry.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"FinMonday achieves another victory by successfully launching its new line of AI-driven financial services.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"Investors celebrate a victory as FinMonday's quarterly earnings exceed all market forecasts.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"FinMonday's commitment to sustainability leads to a victory, winning an award for green financial initiatives.\",\n",
    "    \"sentiment\": \"positive\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"FinMonday faces allegations of fraud as authorities investigate suspicious transactions linked to offshore accounts.\",\n",
    "    \"sentiment\": \"negative\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"Reports emerge of a possible fraud scandal involving FinMonday, leading to increased regulatory scrutiny.\",\n",
    "    \"sentiment\": \"negative\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"FinMonday's reputation takes a hit after whistleblower allegations reveal potential financial fraud.\",\n",
    "    \"sentiment\": \"negative\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"Investors worry as FinMonday's name surfaces in a large-scale fraud investigation led by federal agencies.\",\n",
    "    \"sentiment\": \"negative\"\n",
    "}, {\n",
    "    \"news\":\n",
    "    \"A lawsuit accuses FinMonday of fraud, claiming the company misled clients about its investment strategies.\",\n",
    "    \"sentiment\": \"negative\"\n",
    "}]\n",
    "\n",
    "\n",
    "news_df = pd.DataFrame(news)\n",
    "news_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate:\n",
    "\n",
    "* $P(C=\\text{positive})$\n",
    "* $P(C=\\text{negative})$\n",
    "\n",
    "Now, assume the element we are observing is the presence of the word \"fraud\". Calculate:\n",
    "\n",
    "* $P(f) = P(\\text{has the word 'fraud'})$\n",
    "* $P(f') = P(\\text{does not the word 'fraud'})$\n",
    "\n",
    "Then, estimate:\n",
    "\n",
    "* $P(f | C=\\text{positive})$\n",
    "* $P(f' | C=\\text{negative}) $\n",
    "\n",
    "Last, let's extrapolate the questions:\n",
    "\n",
    "1. Suppose a news piece contains the word fraud. Should we consider it negative news?\n",
    "1. Suppose a news piece does not have the word fraud. Should we consider it positive news?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your solution here\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Naive Bayes approach\n",
    "\n",
    "Of course, in this case, we knew we should be looking at the word \"fraud\". However, in real life, we could be looking at many words - many of which are ambiguous.\n",
    "\n",
    "A naive way of dealing with that is assuming that:\n",
    "\n",
    "1. The occurrence of each word is independent of the other words\n",
    "1. The number of occurences of each word follows a multinomial distribution\n",
    "1. The order of words does not matter, only their presence\n",
    "\n",
    "Condition 1 leads to the Naive Bayes formulation, which is similar to the usual Bayesian formulation, but with many independent variables as conditions for the class.\n",
    "\n",
    "Condition 2 leads to assuming that we need a Multinomial prior in our distribution.\n",
    "\n",
    "Condition 3 leads to using an approach called bag-of-words. In the bag-of-words approach, each word is mapped to a position in a vector. Then, the value in that position is the count of occurrences of that word in the text. In the bag-of-words approach, each text in the collection is considered a collection of words, that is, the order of words is completely disregarded.\n",
    "\n",
    "We don't really want to re-implement all of this. Instead, we will use scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3.08734098e-04 9.99691266e-01]\n",
      " [8.38511701e-06 9.99991615e-01]\n",
      " [3.95440738e-04 9.99604559e-01]\n",
      " [3.35396243e-05 9.99966460e-01]\n",
      " [7.80250876e-04 9.99219749e-01]\n",
      " [6.03729842e-06 9.99993963e-01]\n",
      " [3.37062601e-03 9.96629374e-01]\n",
      " [3.35396243e-05 9.99966460e-01]\n",
      " [5.91504387e-04 9.99408496e-01]\n",
      " [1.67700934e-05 9.99983230e-01]\n",
      " [2.28999856e-04 9.99771000e-01]\n",
      " [2.90539459e-06 9.99997095e-01]\n",
      " [2.10392871e-04 9.99789607e-01]\n",
      " [1.16124698e-03 9.98838753e-01]\n",
      " [3.49441895e-04 9.99650558e-01]\n",
      " [9.99980404e-01 1.95959845e-05]\n",
      " [9.99970683e-01 2.93173437e-05]\n",
      " [9.99902789e-01 9.72108781e-05]\n",
      " [9.99987269e-01 1.27313536e-05]\n",
      " [9.99583506e-01 4.16494245e-04]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data, transform the test data\n",
    "X = vectorizer.fit_transform(news_df['news'])\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X, news_df['sentiment'])\n",
    "\n",
    "# Predict the probability for each class in each news piece:\n",
    "y_pred = clf.predict_proba(X)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy, and train and test sets\n",
    "\n",
    "We have estimated $P(C|X)$. However, this estimate was done on a *sample*. If we wish to understand how much it generalizes to the population (or: to unseen samples), we should test how well it works in *another sample*.\n",
    "\n",
    "To check \"how well it works\", we actually compute the accuracy of the prediction. That is: we choose the most likely class from our predictor - how often is our machine correct?\n",
    "\n",
    "To get *another* population, we need to break our dataset into two datasets: one for training the model, and another one for testing the model.\n",
    "\n",
    "Both of these are already implemented in scikit-learn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df_train, df_test = train_test_split(news_df, test_size=0.2, random_state=2)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data, transform the test data\n",
    "X = vectorizer.fit_transform(df_train['news'])\n",
    "X_test = vectorizer.transform(df_test['news'])\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X, df_train['sentiment'])\n",
    "\n",
    "# Predict the probability for each class in each news piece:\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(df_test['sentiment'], y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now we are getting to a problem. Our dataset is getting *too small* to make an adequate evaluation. We are definitely biasing our model!\n",
    "\n",
    "Now, ok - we need *more* data.\n",
    "\n",
    "Let's leave FinMonday behind. The code below loads the IMDB dataset, which is a famous dataset containing movie reviews. They are tagged as positive and negative.\n",
    "\n",
    "**Exercise: adapt the codes above to get a prediction accuracy score in the IMDB dataset**\n",
    "\n",
    "Remember to:\n",
    "\n",
    "1. Identify what column of the dataframe contains text and what column contains labels\n",
    "1. Split your data into train and test sets\n",
    "1. Train your model in the train set\n",
    "1. Test your model in the test set\n",
    "1. Report accuracy. It will probably be between $0.8$ and $0.9$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /home/tiago/anaconda3/envs/pyeco/lib/python3.13/site-packages (0.3.10)\n",
      "Requirement already satisfied: packaging in /home/tiago/anaconda3/envs/pyeco/lib/python3.13/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /home/tiago/anaconda3/envs/pyeco/lib/python3.13/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/tiago/anaconda3/envs/pyeco/lib/python3.13/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /home/tiago/anaconda3/envs/pyeco/lib/python3.13/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tiago/anaconda3/envs/pyeco/lib/python3.13/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tiago/anaconda3/envs/pyeco/lib/python3.13/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/tiago/anaconda3/envs/pyeco/lib/python3.13/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tiago/anaconda3/envs/pyeco/lib/python3.13/site-packages (from requests->kagglehub) (2024.12.14)\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub\n",
    "import kagglehub\n",
    "path = kagglehub.dataset_download(\"columbine/imdb-dataset-sentiment-analysis-in-csv-format\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "label",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "31f84509-3230-445e-aacc-b586e63db815",
       "rows": [
        [
         "0",
         "I grew up (b. 1965) watching and loving the Thunderbirds. All my mates at school watched. We played \"Thunderbirds\" before school, during lunch and after school. We all wanted to be Virgil or Scott. No one wanted to be Alan. Counting down from 5 became an art form. I took my children to see the movie hoping they would get a glimpse of what I loved as a child. How bitterly disappointing. The only high point was the snappy theme tune. Not that it could compare with the original score of the Thunderbirds. Thankfully early Saturday mornings one television channel still plays reruns of the series Gerry Anderson and his wife created. Jonatha Frakes should hand in his directors chair, his version was completely hopeless. A waste of film. Utter rubbish. A CGI remake may be acceptable but replacing marionettes with Homo sapiens subsp. sapiens was a huge error of judgment.",
         "0"
        ],
        [
         "1",
         "When I put this movie in my DVD player, and sat down with a coke and some chips, I had some expectations. I was hoping that this movie would contain some of the strong-points of the first movie: Awsome animation, good flowing story, excellent voice cast, funny comedy and a kick-ass soundtrack. But, to my disappointment, not any of this is to be found in Atlantis: Milo's Return. Had I read some reviews first, I might not have been so let down. The following paragraph will be directed to those who have seen the first movie, and who enjoyed it primarily for the points mentioned.<br /><br />When the first scene appears, your in for a shock if you just picked Atlantis: Milo's Return from the display-case at your local videoshop (or whatever), and had the expectations I had. The music feels as a bad imitation of the first movie, and the voice cast has been replaced by a not so fitting one. (With the exception of a few characters, like the voice of Sweet). The actual drawings isnt that bad, but the animation in particular is a sad sight. The storyline is also pretty weak, as its more like three episodes of Schooby-Doo than the single adventurous story we got the last time. But dont misunderstand, it's not very good Schooby-Doo episodes. I didnt laugh a single time, although I might have sniggered once or twice.<br /><br />To the audience who haven't seen the first movie, or don't especially care for a similar sequel, here is a fast review of this movie as a stand-alone product: If you liked schooby-doo, you might like this movie. If you didn't, you could still enjoy this movie if you have nothing else to do. And I suspect it might be a good kids movie, but I wouldn't know. It might have been better if Milo's Return had been a three-episode series on a cartoon channel, or on breakfast TV.",
         "0"
        ],
        [
         "2",
         "Why do people who do not know what a particular time in the past was like feel the need to try to define that time for others? Replace Woodstock with the Civil War and the Apollo moon-landing with the Titanic sinking and you've got as realistic a flick as this formulaic soap opera populated entirely by low-life trash. Is this what kids who were too young to be allowed to go to Woodstock and who failed grade school composition do? \"I'll show those old meanies, I'll put out my own movie and prove that you don't have to know nuttin about your topic to still make money!\" Yeah, we already know that. The one thing watching this film did for me was to give me a little insight into underclass thinking. The next time I see a slut in a bar who looks like Diane Lane, I'm running the other way. It's child abuse to let parents that worthless raise kids. It's audience abuse to simply stick Woodstock and the moonlanding into a flick as if that ipso facto means the film portrays 1969.",
         "0"
        ],
        [
         "3",
         "Even though I have great interest in Biblical movies, I was bored to death every minute of the movie. Everything is bad. The movie is too long, the acting is most of the time a Joke and the script is horrible. I did not get the point in mixing the story about Abraham and Noah together. So if you value your time and sanity stay away from this horror.",
         "0"
        ],
        [
         "4",
         "Im a die hard Dads Army fan and nothing will ever change that. I got all the tapes, DVD's and audiobooks and every time i watch/listen to them its brand new. <br /><br />The film. The film is a re run of certain episodes, Man and the hour, Enemy within the gates, Battle School and numerous others with a different edge. Introduction of a new General instead of Captain Square was a brilliant move - especially when he wouldn't cash the cheque (something that is rarely done now).<br /><br />It follows through the early years of getting equipment and uniforms, starting up and training. All in all, its a great film for a boring Sunday afternoon. <br /><br />Two draw backs. One is the Germans bogus dodgy accents (come one, Germans cant pronounced the letter \"W\" like us) and Two The casting of Liz Frazer instead of the familiar Janet Davis. I like Liz in other films like the carry ons but she doesn't carry it correctly in this and Janet Davis would have been the better choice.",
         "1"
        ]
       ],
       "shape": {
        "columns": 2,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I grew up (b. 1965) watching and loving the Th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I put this movie in my DVD player, and sa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why do people who do not know what a particula...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Even though I have great interest in Biblical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Im a die hard Dads Army fan and nothing will e...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I grew up (b. 1965) watching and loving the Th...      0\n",
       "1  When I put this movie in my DVD player, and sa...      0\n",
       "2  Why do people who do not know what a particula...      0\n",
       "3  Even though I have great interest in Biblical ...      0\n",
       "4  Im a die hard Dads Army fan and nothing will e...      1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(path + \"/Train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.85\n"
     ]
    }
   ],
   "source": [
    "# This is my solution, but do NOT copy it! Try to solve it on your own first.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Split the data into train and test sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit and transform the training data, transform the test data\n",
    "X_train = vectorizer.fit_transform(df_train['text'])\n",
    "X_test = vectorizer.transform(df_test['text'])\n",
    "\n",
    "# Initialize the Multinomial Naive Bayes model\n",
    "clf = MultinomialNB()\n",
    "\n",
    "# Train the model\n",
    "clf.fit(X_train, df_train['label'])\n",
    "\n",
    "# Predict the labels for the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(df_test['label'], y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review and exercises\n",
    "\n",
    "At this point, you should be ok with:\n",
    "\n",
    "* Splitting data into train and test\n",
    "* Using a vectorizer\n",
    "* Using a Multinomial Naive Bayes machine\n",
    "* Reporting accuracy\n",
    "\n",
    "Now, let's proceed to some exercises:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 1\n",
    "# Find another dataset on Kaggle that contains text data and labels. \n",
    "# Use the Naive Bayes classifier to predict the labels of the text data. \n",
    "# Report the accuracy of your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 2\n",
    "# What happens to the classification accuracy if we shuffle the words in a text document?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Challenge 3\n",
    "# Choose one topic that has been in the news lately.\n",
    "# Download news about that topic from a news website or use a news API to get the latest news.\n",
    "# Use Excel or another spreadsheet program to label the news as positive or negative.\n",
    "# Use the Naive Bayes classifier to predict the sentiment of the news.\n",
    "# Report the accuracy of your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyeco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
