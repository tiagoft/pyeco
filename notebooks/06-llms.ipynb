{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Large Language Models\n",
    "\n",
    "There has been a huge hype around the easily-accessible Large Language Models (LLMs). Tools such as ChatGPT, CoPilot, and so on, keep appearing in new brands and versions every week. This technology is being largely discussed due to their ethical and technical implications, and it is likely that they are going to stay around (officially or not) for at least a few years.\n",
    "\n",
    "## How LLMs work\n",
    "\n",
    "Language Models are predictors. They have been trained to predict a distribution of probabilities for a next word given $k$ previous words (which are called *context*), that is:\n",
    "\n",
    "$$\n",
    "P(w_n | w_{n-1}, w_{n-2} \\cdots w_{n-k})\n",
    "$$\n",
    "\n",
    "The model selects the next word by sampling from the distribution $P(w_n | w_{n-1}, w_{n-2} \\cdots w_{n-k})$. After that, the predicted word is injected into the context (and possibly the $k$-th word is discarded) and the prediction is executed again. This is called *autorregressive generation*.\n",
    "\n",
    "## Strengths of LLMs\n",
    "\n",
    "LLMs are able to predict words based on training data, that is, they are able to *mimic* texts that have been previously seen. However, this is a clever mimic in which the model is able to recombine previous sentences. For example, a model trained on \"I took my dogs for a walk\" and \"I took my children to the park\" could combine these sentences and yield: \"I took my dog to the park\".\n",
    "\n",
    "Also, within the training data, there are dialogues, requests, and so on. As a consequence, the model is able to identify which of the $k$ previous words are more relevant to predict the next ones considering the context they are in: is this a conversation? A lecture? Should the prediction be as if it was a specialist? Or a student? Or should we only use words that children can understand?\n",
    "\n",
    "Hence, by populating the context (that is, the previous $k$ words) with phrases that make sense towards a particular problem, we can explicitly \"ask\" the model, using natural language, to behave as something specific. There are many strategies for such:\n",
    "\n",
    "## Strategies for LLMs\n",
    "\n",
    "Before experimenting with these strategies, navigate to [Google AI Studio](https://aistudio.google.com/prompts/new_chat) and, if necessary, create a free account. We will start from there.\n",
    "\n",
    "### Chatting and behavior\n",
    "\n",
    "\n",
    "#### Chat\n",
    "\n",
    "In the *create prompt* tab, you might be seeing a panel in the bottom saying: \"type something\". Go ahead and type: \"hello, LLM model. I am a student trying to figure out how to use LLMs for good, without incurring in ethical issues. Can you help me with that?\".\n",
    "\n",
    "The model will probably give you a lot of information. Save that for later - we will first explore the possibilities here.\n",
    "\n",
    "#### System prompt\n",
    "\n",
    "Take a look at the panel at the top, which says: \"system instructions\". You can use the system instructions to set the tone, style, and typical behaviors of your system. For example: set the system instructions to:  \"You are a wicked witch living in a forest. You answer everything very shortly, and always makes a reference to your house made of candy, and you creeply invite people to come in.\" and then ask again: \"Hi. Can you tell me about LLMs?\"\n",
    "\n",
    "#### Temperature\n",
    "\n",
    "Temperature is a parameter used in the sampling process (when a new word is being sampled from the conditional distribution). The name \"temperature\" is a metaphor for annealing processes used to make metals. Higher temperature means the distribution converted to \"more similar to a uniform distribution\", whereas lower temperatures make the outputs closer to deterministic. Move the temperature slider left and right and try asking the same thing over and over again. What happens?\n",
    "\n",
    "### Zero-shot prompting\n",
    "\n",
    "Because LLMs have been trained on a lot of data, it might yield some texts that make a lot of sense. This is not *creative* or *intelligent* - rather, it is a recombination of texts that most humans are likely not to have read.\n",
    "\n",
    "Use the system prompt to give your LLM some personality that could be useful for your research (for example: do you need an advisor? Do you need to talk to a specialist?).\n",
    "\n",
    "One of my favourite ways to use it is to make the LLM pretend that it is a reviewer for my paper: \"You are reviewer 2. You are going to find reasons to reject my paper, and ground them in actual facts. Also, give constructive feedback by indicating the ways each of the points could be addressed. However, we cannot run the experiment again - we can only rewrite the paper\". This gives me timely, constructive feedback on my work, and often raises important points to discuss.\n",
    "\n",
    "One important ethical consideration here is that many communities consider wrong or unethical to ask the LLM to write or generate deliverables for you. This is because science is highly grounded in trust and liability, and a machine that predicts the next work has neither - even if the final product is of decent quality. People reading your paper want to read *your* words, not simply those automatically generated.\n",
    "\n",
    "On the other hand, other communities believe LLMs are powerful productivity tools, and their usage is advantageous. LLMs can especially benefit non-native speakers of some language by rephrasing sentences to a specific style. Try getting a difficult passage from this lesson, for example, and change its style to the lyrics of your favourite style.\n",
    "\n",
    "### Few-shot prompting\n",
    "\n",
    "Although LLMs have been trained on a huge amount of texts, thus are theoretically capable of generating any book contemporary humans have ever read, this does not means that it can, spot on, generate the exact content that we want. An idea that has shown to work well is to provide the LLM with some examples within the context, that is: \"do X, Y, Z. Some examples are: A, B, C. The actual material to work with is: [the material]\".\n",
    "\n",
    "It is hard to know exactly what examples, and how many examples, are necessary. What usually happens is that we start with zero-shot prompting and start adding examples as needed by analyzing the results.\n",
    "\n",
    "### Retrieval-Augmented Generation (RAG)\n",
    "\n",
    "LLMs work somewhat well at rephrasing and summarizing, but, to generate content in a zero-shot setting, they can randomly create gibberish (even if it is gibberish that reads well-articulated). To solve this, we could, instead of asking for a \"generation\", ask for a summary of a text that we know will possibly contain the answer for our question. For example, we might wish to understand how LLMs perform in sentiment analysis. If we get [this paper](https://arxiv.org/abs/2305.15005), we can find interesting material to summarize. However, we can, maybe, get 3 different papers on this same topic:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper1 = \"\"\"Sentiment Analysis in the Era of Large Language Models: A Reality Check\n",
    "Wenxuan Zhang, Yue Deng, Bing Liu, Sinno Jialin Pan, Lidong Bing\n",
    "Sentiment analysis (SA) has been a long-standing research area in natural language processing. It can offer rich insights into human sentiments and opinions and has thus seen considerable interest from both academia and industry. With the advent of large language models (LLMs) such as ChatGPT, there is a great potential for their employment on SA problems. However, the extent to which existing LLMs can be leveraged for different sentiment analysis tasks remains unclear. This paper aims to provide a comprehensive investigation into the capabilities of LLMs in performing various sentiment analysis tasks, from conventional sentiment classification to aspect-based sentiment analysis and multifaceted analysis of subjective texts. We evaluate performance across 13 tasks on 26 datasets and compare the results against small language models (SLMs) trained on domain-specific datasets. Our study reveals that while LLMs demonstrate satisfactory performance in simpler tasks, they lag behind in more complex tasks requiring deeper understanding or structured sentiment information. However, LLMs significantly outperform SLMs in few-shot learning settings, suggesting their potential when annotation resources are limited. We also highlight the limitations of current evaluation practices in assessing LLMs' SA abilities and propose a novel benchmark, \\textsc{SentiEval}, for a more comprehensive and realistic evaluation\"\"\"\n",
    "\n",
    "paper2 = \"\"\"Sentiment Analysis through LLM Negotiations\n",
    "Xiaofei Sun, Xiaoya Li, Shengyu Zhang, Shuhe Wang, Fei Wu, Jiwei Li, Tianwei Zhang, Guoyin Wang\n",
    "A standard paradigm for sentiment analysis is to rely on a singular LLM and makes the decision in a single round under the framework of in-context learning. This framework suffers the key disadvantage that the single-turn output generated by a single LLM might not deliver the perfect decision, just as humans sometimes need multiple attempts to get things right. This is especially true for the task of sentiment analysis where deep reasoning is required to address the complex linguistic phenomenon (e.g., clause composition, irony, etc) in the input.\n",
    "To address this issue, this paper introduces a multi-LLM negotiation framework for sentiment analysis. The framework consists of a reasoning-infused generator to provide decision along with rationale, a explanation-deriving discriminator to evaluate the credibility of the generator. The generator and the discriminator iterate until a consensus is reached. The proposed framework naturally addressed the aforementioned challenge, as we are able to take the complementary abilities of two LLMs, have them use rationale to persuade each other for correction.\n",
    "Experiments on a wide range of sentiment analysis benchmarks (SST-2, Movie Review, Twitter, yelp, amazon, IMDB) demonstrate the effectiveness of proposed approach: it consistently yields better performances than the ICL baseline across all benchmarks, and even superior performances to supervised baselines on the Twitter and movie review datasets.\n",
    "\"\"\"\n",
    "\n",
    "paper3 = \"\"\"Sentiment Analysis in the Age of Generative AI\n",
    "Jan Ole Krugmann, Jochen Hartmann \n",
    "In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs’ proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then, we can automatically make a prompt including the three texts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Make a summary of the current state of affairs in Sentiment Analysis using LLMs. Find conflicting perspectives and cite sources. Use these references:\n",
      "Paper 1: Sentiment Analysis in the Era of Large Language Models: A Reality Check\n",
      "Wenxuan Zhang, Yue Deng, Bing Liu, Sinno Jialin Pan, Lidong Bing\n",
      "Sentiment analysis (SA) has been a long-standing research area in natural language processing. It can offer rich insights into human sentiments and opinions and has thus seen considerable interest from both academia and industry. With the advent of large language models (LLMs) such as ChatGPT, there is a great potential for their employment on SA problems. However, the extent to which existing LLMs can be leveraged for different sentiment analysis tasks remains unclear. This paper aims to provide a comprehensive investigation into the capabilities of LLMs in performing various sentiment analysis tasks, from conventional sentiment classification to aspect-based sentiment analysis and multifaceted analysis of subjective texts. We evaluate performance across 13 tasks on 26 datasets and compare the results against small language models (SLMs) trained on domain-specific datasets. Our study reveals that while LLMs demonstrate satisfactory performance in simpler tasks, they lag behind in more complex tasks requiring deeper understanding or structured sentiment information. However, LLMs significantly outperform SLMs in few-shot learning settings, suggesting their potential when annotation resources are limited. We also highlight the limitations of current evaluation practices in assessing LLMs' SA abilities and propose a novel benchmark, \textsc{SentiEval}, for a more comprehensive and realistic evaluation\n",
      "Paper 2: Sentiment Analysis through LLM Negotiations\n",
      "Xiaofei Sun, Xiaoya Li, Shengyu Zhang, Shuhe Wang, Fei Wu, Jiwei Li, Tianwei Zhang, Guoyin Wang\n",
      "A standard paradigm for sentiment analysis is to rely on a singular LLM and makes the decision in a single round under the framework of in-context learning. This framework suffers the key disadvantage that the single-turn output generated by a single LLM might not deliver the perfect decision, just as humans sometimes need multiple attempts to get things right. This is especially true for the task of sentiment analysis where deep reasoning is required to address the complex linguistic phenomenon (e.g., clause composition, irony, etc) in the input.\n",
      "To address this issue, this paper introduces a multi-LLM negotiation framework for sentiment analysis. The framework consists of a reasoning-infused generator to provide decision along with rationale, a explanation-deriving discriminator to evaluate the credibility of the generator. The generator and the discriminator iterate until a consensus is reached. The proposed framework naturally addressed the aforementioned challenge, as we are able to take the complementary abilities of two LLMs, have them use rationale to persuade each other for correction.\n",
      "Experiments on a wide range of sentiment analysis benchmarks (SST-2, Movie Review, Twitter, yelp, amazon, IMDB) demonstrate the effectiveness of proposed approach: it consistently yields better performances than the ICL baseline across all benchmarks, and even superior performances to supervised baselines on the Twitter and movie review datasets.\n",
      "\n",
      "Paper 3: Sentiment Analysis in the Age of Generative AI\n",
      "Jan Ole Krugmann, Jochen Hartmann \n",
      "In the rapidly advancing age of Generative AI, Large Language Models (LLMs) such as ChatGPT stand at the forefront of disrupting marketing practice and research. This paper presents a comprehensive exploration of LLMs’ proficiency in sentiment analysis, a core task in marketing research for understanding consumer emotions, opinions, and perceptions. We benchmark the performance of three state-of-the-art LLMs, i.e., GPT-3.5, GPT-4, and Llama 2, against established, high-performing transfer learning models. Despite their zero-shot nature, our research reveals that LLMs can not only compete with but in some cases also surpass traditional transfer learning methods in terms of sentiment classification accuracy. We investigate the influence of textual data characteristics and analytical procedures on classification accuracy, shedding light on how data origin, text complexity, and prompting techniques impact LLM performance. We find that linguistic features such as the presence of lengthy, content-laden words improve classification performance, while other features such as single-sentence reviews and less structured social media text documents reduce performance. Further, we explore the explainability of sentiment classifications generated by LLMs. The findings indicate that LLMs, especially Llama 2, offer remarkable classification explanations, highlighting their advanced human-like reasoning capabilities. Collectively, this paper enriches the current understanding of sentiment analysis, providing valuable insights and guidance for the selection of suitable methods by marketing researchers and practitioners in the age of Generative AI.\n",
      "\n",
      "\n",
      "Also, give the output written as an excertp of a literature review. Use all citations in APA style. Do not use superlatives or embelishment at all.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Make a summary of the current state of affairs in Sentiment Analysis using LLMs. Find conflicting perspectives and cite sources. Use these references:\n",
    "Paper 1: {paper1}\n",
    "Paper 2: {paper2}\n",
    "Paper 3: {paper3}\n",
    "\n",
    "Also, give the output written as an excertp of a literature review. Use all citations in APA style. Do not use superlatives or embelishment at all.\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using prompts within programming\n",
    "\n",
    "If you browse straight to https://ai.google.dev/gemini-api/docs, you will find an example of how google's GenAI API works. You will need to install a package (`pip install google-genai`) before using the code. Also, you will need to get an API key from Google. We can start with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "client = genai.Client(api_key=\"YOUR_API_KEY\") # Get your API key at the Google AI Studio website!\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt,\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is nice, but let's improve our prompting so that it can be embedded into our workflow:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"Title\": \"Sentiment Analysis in the Era of Large Language Models: A Reality Check\",\n",
      "    \"Authors\": [\n",
      "      {\n",
      "        \"Name\": \"Wenxuan Zhang\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Yue Deng\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Bing Liu\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Sinno Jialin Pan\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Lidong Bing\"\n",
      "      }\n",
      "    ],\n",
      "    \"Main conclusion\": \"LLMs show satisfactory performance in simpler sentiment analysis tasks, but lag behind small language models (SLMs) in more complex tasks that require deeper understanding. However, LLMs outperform SLMs in few-shot learning, which means that LLMs are useful when there are few examples for training the models.\"\n",
      "  },\n",
      "  {\n",
      "    \"Title\": \"Sentiment Analysis through LLM Negotiations\",\n",
      "    \"Authors\": [\n",
      "      {\n",
      "        \"Name\": \"Xiaofei Sun\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Xiaoya Li\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Shengyu Zhang\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Shuhe Wang\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Fei Wu\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Jiwei Li\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Tianwei Zhang\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Guoyin Wang\"\n",
      "      }\n",
      "    ],\n",
      "    \"Main conclusion\": \"A multi-LLM negotiation framework, where LLMs reason with each other iteratively, improves sentiment analysis performance compared to a single LLM making a decision in one round. This approach can even outperform supervised baselines on some datasets.\"\n",
      "  },\n",
      "  {\n",
      "    \"Title\": \"Sentiment Analysis in the Age of Generative AI\",\n",
      "    \"Authors\": [\n",
      "      {\n",
      "        \"Name\": \"Jan Ole Krugmann\"\n",
      "      },\n",
      "      {\n",
      "        \"Name\": \"Jochen Hartmann\"\n",
      "      }\n",
      "    ],\n",
      "    \"Main conclusion\": \"Large Language Models (LLMs) can compete with and sometimes surpass traditional transfer learning methods in sentiment classification accuracy, even in zero-shot settings. The performance is influenced by data characteristics, text complexity, and prompting techniques and that LLMs can give human-like reasoning for their sentiment classifications.\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from google import genai\n",
    "\n",
    "\n",
    "prompt = f\"\"\"Make a summary of the current state of affairs in Sentiment Analysis using LLMs. Find conflicting perspectives and cite sources. Use these references:\n",
    "Paper 1: {paper1}\n",
    "Paper 2: {paper2}\n",
    "Paper 3: {paper3}\n",
    "\n",
    "We need the output in a JSON format, using the following schema:\n",
    "Author = {{'Name' : str}} # Each of the authors of the paper\n",
    "Paper = {{'Title' : str, # the paper title \n",
    "  'Authors' : list[Author],\n",
    "  'Main conclusion' : str # the main conclusion of the paper \n",
    "}}\n",
    "Return: list[Paper]\n",
    "\"\"\"\n",
    "\n",
    "client = genai.Client(api_key=\"AIzaSyCcuZKxUQTWtWGOCAH6f8TQLcDM_q_U7pM\") # Get your API key at the Google AI Studio website!\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    contents=prompt,\n",
    "    config={\n",
    "        'response_mime_type': 'application/json', # This part is VERY IMPORTANT!\n",
    "    },\n",
    "\n",
    ")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can import our json document to a dictionary and make a dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Main conclusion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentiment Analysis in the Era of Large Languag...</td>\n",
       "      <td>[{'Name': 'Wenxuan Zhang'}, {'Name': 'Yue Deng...</td>\n",
       "      <td>LLMs show satisfactory performance in simpler ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentiment Analysis through LLM Negotiations</td>\n",
       "      <td>[{'Name': 'Xiaofei Sun'}, {'Name': 'Xiaoya Li'...</td>\n",
       "      <td>A multi-LLM negotiation framework, where LLMs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentiment Analysis in the Age of Generative AI</td>\n",
       "      <td>[{'Name': 'Jan Ole Krugmann'}, {'Name': 'Joche...</td>\n",
       "      <td>Large Language Models (LLMs) can compete with ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  Sentiment Analysis in the Era of Large Languag...   \n",
       "1        Sentiment Analysis through LLM Negotiations   \n",
       "2     Sentiment Analysis in the Age of Generative AI   \n",
       "\n",
       "                                             Authors  \\\n",
       "0  [{'Name': 'Wenxuan Zhang'}, {'Name': 'Yue Deng...   \n",
       "1  [{'Name': 'Xiaofei Sun'}, {'Name': 'Xiaoya Li'...   \n",
       "2  [{'Name': 'Jan Ole Krugmann'}, {'Name': 'Joche...   \n",
       "\n",
       "                                     Main conclusion  \n",
       "0  LLMs show satisfactory performance in simpler ...  \n",
       "1  A multi-LLM negotiation framework, where LLMs ...  \n",
       "2  Large Language Models (LLMs) can compete with ...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "\n",
    "data = json.loads(response.text)\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Challenge\n",
    "\n",
    "LLMs are a very recent advance. Every week or two, there is a new model coming up. The challenge here is to find how to use them in your workflow. LLMs have shown to be useful to summarize texts - and information retrieval is one of the many perspectives towards summarization.\n",
    "\n",
    "Now it is on your hands. Let's do the following:\n",
    "\n",
    "1. Find three articles that are relevant to your field of study, and that are recent enough (post-2022).\n",
    "1. Use the procedure we have done above to find their main conclusions, their arguments, and other information you might find relevant to your research.\n",
    "1. Save the dataframe you generated as an excel spreadsheet. Check if all information is correct, and, if necessary, correct it.\n",
    "1. Use the results as a source to make a paragraph with a literature review for the three articles. Evaluate the literature review. What could be improved in it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyeco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
